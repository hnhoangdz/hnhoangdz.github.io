---
layout: post
author: dinhhuyhoang
title: Bài 5 - K-means
---

**Phụ lục:**

- [1. Giới thiệu](#1-introduction)
- [2. Lập công thức chung](#2-generalization)
- [3. Thực nghiệm với Python](#3-coding)
- [4. Learning rate](#4-learning-rate)
- [5. Đánh giá và kết luận](#5-evaluation)
- [6. Tham khảo](#6-references)

<a name="1-introduction"></a>

## 1. Giới thiệu

Trong thực tế, những bài toán như dự báo, phân loại yêu cầu phần lớn dữ liệu cần phải gán nhãn. Vậy nếu khi có một tập dữ liệu về khách hàng như: sở thích, thói quen, giới tính, độ tuổi... làm sao để phân loại khách hàng nào là tiềm năng hoặc không trong khi các dữ liệu chưa được gán nhãn. Việc đi tìm nhãn cho khách hàng (dữ liệu) chính là mục tiêu của thuật toán K-means. Và sau khi gán nhãn cho khách hàng thành công, khi một khách hàng mới đến ta có thể trả lời rằng người này thuộc nhóm khách hàng tiềm năng hay không, từ đó có thể phát triển rất nhiều chiến lược về khuyến mại và marketing.

Khác với các bài toán thuộc học có giám sát (supervised-learning) - các biến mục tiêu đã biết, K-means là lớp bài toán thuộc học không giám sát (unsupervised-learning) - các biến mục tiêu chưa biết.

<img src="/assets/images/bai5/anh1.png" class="normalpic"/>

<p align="center"> <b>Hình 1</b>: Sự khác biệt giữa supervised và unsupervised</p>

## 2. Kết quả mong muốn 

Trong thuật toán K-means, với tập dữ liệu có $m$ samples. Ta cần phân nhóm $m$ samples thành $k$ cụm, với mỗi cụm sẽ có độ tương đồng về dữ liệu nhất định (có thể là sở thích, tích cách...). Với hình 1 bên phải, tức ta cần phân nhóm 9 samples thành 2 cụm: màu xanh lục và màu đỏ. Giả sử với tập dữ liệu 2 chiều sau:

<img src="/assets/images/bai5/anh2.png" class="normalpic"/>

<p align="center"> <b>Hình 2</b>: Visualize dữ liệu (<b>Source: </b><a href="https://www.coursera.org/learn/machine-learning/lecture/93VPG/k-means-algorithm">Machine learning - Coursera</a>)</p>

Với thuật toán K-means, ta cần lựa chọn số lượng cụm như là hyper-parameter đầu vào. Với hình trên thì ta có thể thấy số lượng cụm là 2 khá hợp lí. Vì vậy, từ dữ liệu đầu vào và số lượng nhóm chúng ta muốn tìm, hãy chỉ ra center (điểm trung tâm cụm) của mỗi nhóm và phân các điểm dữ liệu vào các nhóm tương ứng. Giả sử thêm rằng mỗi điểm dữ liệu chỉ thuộc vào đúng một nhóm. Ta mong muốn kết quả như sau:

<img src="/assets/images/bai5/anh3.png" class="normalpic"/>

<p align="center"> <b>Hình 3</b>: Kết quả</p>

Như hình trên, ta thấy 2 cụm xanh và đỏ riêng biệt đã được phân riêng rẽ. Hơn nữa 2 điểm trung tâm (center cluster) - kí hiệu 'x' là tâm mỗi cụm.

## 3. Hàm mất mát

Giả sử ta có $m$ điểm dữ liệu. $\mathbf{X} = \begin{bmatrix} x^{(1)}, x^{(2)}, x^{(3)},...x^{(m)} \end{bmatrix}$ trong đó $x^{(i)} \in \mathbb{R}^d $, $i$ chạy từ 1,2,...$m$ và $\mathbf{X} \in \mathbb{R}^{d \times m}$. Có $K$ cụm với $K < m$. Đặt $c_k$ là tâm cụm ta đã tìm được và $x^{(i)}$ là điểm dữ liệu thuộc cụm này. Điều ta mong muốn là khoảng cách (sai số) giữa $c_k$ và $x_i$ là nhỏ nhất có thể. Và sai số trên toàn tập dữ liệu là. 

$$J = \sum_{j=1}^K\sum_{i=1}^m \|\mathbf{x}^i:j - \mathbf{c}_j\|_2^2 (1)$$

Ở công thức (1) ta hiểu là: tổng sai số bằng tổng khoảng cách của tâm cụm $j$ với các điểm dữ liệu $x_i$ thuộc cụm $j$. Trong đó $j$ được hiểu ngầm là nhãn cho dữ liệu vì vậy ta sẽ có $K$ nhãn khác nhau. Công thức này sai về mặt toán học, nhưng nó khá dễ hiểu với mình để diễn đạt. Và $c_j$ là trung bình cộng của các điểm thuộc cụm $j$.

Ở đây, mình đã đơn giản hóa cách biểu diễn để khi thực code sẽ dễ dàng hơn, bạn có thể đọc thêm [tại đây](https://machinelearningcoban.com/2017/01/01/kmeans/#-phan-tich-toan-hoc) để xem cách biểu diễn dạng vector one-hot và chứng minh tâm cụm là trung bình cộng của các điểm dữ liệu thuộc cụm đó.

## 4. Các bước giải bài toán

**Bước 1**: Chọn $K$ điểm dữ liệu làm điểm tâm cụm ban đầu. 

**Bước 2**: Tính khoảng cách mỗi điểm dữ liệu với tâm cụm và gán dữ liệu vào cụm gần nhất.

**Bước 3**: Nếu việc gán dữ liệu vào từng cluster ở bước 2 không thay đổi so với vòng lặp trước nó thì ta dừng thuật toán.

**Bước 4**: Cập nhật điểm tâm cụm bằng trung bình cộng các dữ liệu thuộc cụm đó.

**Bước 5**: Quay lại bước 2.

## 5. Thực nghiệm với Python

```python
import numpy as np # ĐSTT
import random # Make the dataset
import matplotlib.pyplot as plt # Visualize
from sklearn.datasets import make_blobs # Make the dataset

# Visualize dữ liệu
centers = [[1, 1], [-1, -1], [1, -1]] 
X, true_labels = make_blobs(n_samples=750, centers=centers, 
                            cluster_std=0.4, random_state=0)
plt.plot(X[:,0],X[:,1],'o')
plt.title('Dataset')
```

<img src="/assets/images/bai5/anh4.png" class="normalpic"/>

<p align="center"> <b>Hình 4</b>: Visualize dataset</p>


