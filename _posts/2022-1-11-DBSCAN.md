---
layout: post
author: dinhhuyhoang
title: Bài 11 - DBSCAN
---

## 1. Giới thiệu

Ở [bài 7](https://hnhoangdz.github.io/2021/11/21/Kmeans.html) mình đã trình bày về một thuật toán unsupervised - K-means clustering, mục đích của thuật toán này là gom những cụm dữ liệu có cùng độ tương đồng nào đó về thành một nhóm. Bên cạnh một số ưu điểm của thuật toán này thì một điểm yếu lớn của K-means là toàn bộ dữ liệu sẽ ảnh hưởng tới tâm cụm tìm được tức sẽ bị ảnh hưởng bởi nhiễu (outlier). Vì vậy, trong thuật toán DBSCAN hôm nay mà mình sẽ trình bày sẽ giúp khắc phục được điểm yếu này (phát hiện outlier). Nhưng liệu sau khi đã phát hiện được outlier và bỏ qua chúng thì việc sử dụng thuật toán K-means tiếp theo sẽ tốt hơn? Câu trả lời là có và không. Để hiểu hơn hãy xem ví dụ minh họa về sự khác biệt của 2 thuật toán này:

<img src="/assets/images/bai11/anh1.png" class="normalpic"/>

<p align="center"> <b>Hình 1</b>: DBSCAN vs K-means</p>

Như đã thấy ở hình trên, thuật toán DBSCAN có chiến lược phân cụm hoàn toàn khác so với K-means (dữ liệu hình vuông cuối cùng bên phải thể hiện rõ điều này). Từ đây nhận ra rằng với DBSCAN bên trong mỗi cụm sẽ có mật độ dữ liệu cao hơn bên ngoài cụm. Hơn nữa, những điểm outlier thì sẽ có mật độ rất rất thưa.

Vậy thuật toán DBSCAN làm việc như thế nào để tìm ra cụm và điểm nhiễu, mình sẽ trình bày bên dưới.

## 2. Các định nghĩa trong DBSCAN

Có một số định nghĩa về mặt lí thuyết của thuật toán DBSCAN (phần này cũng không quá quan trọng trong việc hiểu ý tưởng thuật toán, bạn có thể bỏ qua), nên mình sẽ dịch lại các định nghĩa của [bài báo gốc](https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf):

**Định nghĩa 1:** Vùng lân cận $\epsilon$ (Epsilon-neighborhood)

Gọi $D$ là tập hợp các điểm trong cơ sở dữ liệu. $p$ là một điểm dữ liệu bất kì thuộc $D$, $\epsilon$ là một hằng số xác định. Tập hợp các điểm lân cận của $p$ có khoảng cách nhỏ hơn $\epsilon$ là:

$$N_{eps}(p) = \{q \in \mathcal{D}: d(p, q) \leq \epsilon\}$$

**Định nghĩa 2:** Khả năng tiếp cận trực tiếp mật độ (directly density-reachable)

Một điểm $p \in D$ là directly density - reachable từ một điểm $ q ∈ D $ tương ứng với tham số `epsilon` và `minPoints` nếu như nó thoả mãn hai điều kiện:

$$(1) p \in N_{eps}(p)$$

$$(2) |N_{eps}(p)| \geq \text{minPoints}$$

trong đó `minPoints` cũng là một hằng số xác định nhằm đảm bảo một lượng đủ mật độ để xác định điểm cốt lõi (core point).

**Định nghĩa 3:** Khả năng tiếp cận mật độ (density-reachable)

Một điểm $p$ là density–reachable từ $q$ khi và chỉ khi có một dây chuyền các điểm $p_1, …, p_n$ với $p_1 = q$ và $p_n = p$ mà $p_i+1$ là directly density – reachable từ $p_i$.

Hai điểm nằm trên biên của một nhóm thì không density–reachable lẫn nhau, bởi vì điều kiện xác định điểm lõi không chứa chúng. Tuy nhiên, trong nhóm sẽ có một điểm lõi mà hai điểm biên đều density–reachable.

**Định nghĩa 4:** Kết nối mật độ (density-connected)

Một điểm $p$ là density-connected đến một điểm $q$ khi và chỉ khi có một điểm $o$ mà cả hai điểm $p$ và $q$ đều density-reachable từ $o$. 

**Định nghĩa 5:** Nhóm (cluster)

Một nhóm $C$ là một tập con không rỗng của $D$ thỏa các điều kiệu sau:

- $∀ p, q$: nếu $p ∈ C$ và $q$ là density-reachable từ $p$ thì $q ∈ C$.

- $∀ p, q ∈ C: p$ là density-connected từ $q$.

**Định nghĩa 6:** Nhiễu (noise)

Gọi $C_1, …, C_k$ là các nhóm của tập dữ liệu $D$. Nhiễu là tập hợp tất cả các điểm không thuộc bất kỳ nhóm $C_i$ nào với $i=1, …, k$.

## 3. Các loại điểm dữ liệu trong DBSCAN

Tóm tắt lại đoạn định nghĩa ở phần trên như sau: 

- Vùng lân cận $\epsilon$ là vòng tròn bánh kính bằng $\epsilon$ được vẽ xunh quanh điểm $p \in D$ để quét số lượng điểm rơi bên trong vòng tròn này.

- Sử dụng `minPoints` làm ngưỡng xác định xem vùng lân cận $\epsilon$ có số điểm dữ liệu tối thiểu để trở thành: core point hay Boder point hay noise.

### 3.1. Core point

Core point là điểm có số điểm vùng lân cận nhiều hơn hoặc bằng `minPoints` (tính cả điểm đang xét), ví dụ với `minPoints` bằng 5 các điểm tròn màu đỏ là core point và màu xanh không phải core point:

<img src="/assets/images/bai11/anh2.png" class="normalpic"/>

<p align="center"> <b>Hình 2</b>: Core point</p>

### 3.2. Boder point  

Boder point là điểm có vùng lân cận chứa ít điểm hơn `minPoints` nhưng có điểm ở vùng lân cận của điểm cốt lõi (core point), ví dụ minh họa `minPoints` bằng 5:

<img src="/assets/images/bai11/anh3.png" class="smallpic"/>

<p align="center"> <b>Hình 3</b>: Boder point</p>

### 3.3. Noise point 

Noise point là điểm dữ liệu nhiễu: số lượng điểm lân cận nhỏ hơn `minPoints` và không có điểm lân cận nào nằm trong vùng lân cận có core point, ví dụ minh họa:

<img src="/assets/images/bai11/anh4.png" class="smallpic"/>

<p align="center"> <b>Hình 4</b>: Noise point</p>

### 3.4. Ví dụ tổng quát 

Với `minPoints` bằng 4, các điểm màu đỏ là core point, màu vàng là Boder point, xanh dương là noise point.

<img src="/assets/images/bai11/anh5.png" class="smallpic"/>

<p align="center"> <b>Hình 4</b>: Noise point</p>

## 4. Cách thức hoạt động

### 4.1. Minh họa hình ảnh

<img src="/assets/images/bai11/dbscan.gif" class="normalpic"/>

<p align="center"> <b>Hình 5</b>: Cách DBSCAN hoạt động</p>

Như bạn đã thấy, thuật toán DBSCAN sẽ dựa trên 2 tham số `epsilon` và `minPoints` để tiến hành phân cụm. Quá trình phân cụm sẽ dựa trên một điểm khởi tạo ban đầu, nếu là core point nó sẽ tiếp tục lan truyền mật độ dần dần để mở rộng phạm vi của cụm cho tới khi chạm được hết các điểm border point. Sau khi đã chạm được các điểm border point, thì các điểm chưa được xét sẽ tiếp tục được tính toán dựa trên 2 tham số `epsilon` và `minPoints` cho tới khi toàn bộ dữ liệu đã được xét.

### 4.2. Các bước giải bài toán

**Bước 1:** Chọn 1 điểm $p$ từ tập dữ liệu

**Bước 2:** Tìm toàn bộ những vùng lân cận của $p$ với điều kiện thỏa mãn tham số `epsilon`:

$$N_{eps}(p) = \{q \in \mathcal{D}: d(p, q) \leq \epsilon\}$$

**Bước 3:** Xác định xem $p$ có thể là core point thỏa mãn điều kiện sau với tham số `minPoints`:

$$|N_{eps}(p)| \geq \text{minPoints}$$

**Bước 4:** Nếu $p$ là core point, tiếp tục mở rộng vùng lân cận của các điểm thuộc lân cận của $p$ và xác định như bước 2 và bước 3.

**Bước 5:** Tiếp thuật cho tới khi toàn bộ dữ liệu đã được xử lí.

**Lưu ý:** Ở các bước 1, 2, 3, 4 phải thỏa mãn điều kiện điểm $p$ chưa được xét tới bao giờ.

## 5. Thực nghiệm với Python

Ở phần này, mình sẽ trình bày 2 phương pháp giải: tự implement và thư viện. Sau đó mình sẽ sử dụng kết quả của 2 phương pháp để so sánh xem cách mình tự implement đã đúng chưa. Ngoài ra, mình sẽ sử dụng lại bộ datasets đã thực hiện với bài toán K-means và để so sánh sự khác nhau giữa 2 thuật toán này.

```python
import numpy as np # ĐSTT
import random 
import matplotlib.pyplot as plt # Visualize
from sklearn.datasets import make_blobs # Make the dataset

# Init original centroids
true_centroids = [[1, 1], [-1, -1], [1, -1]] 
# dataset
X, true_labels = make_blobs(n_samples=750, centers=true_centroids, 
                            cluster_std=0.4, random_state=0)
# Visualize dữ liệu
plt.plot(X[:,0],X[:,1],'o')
plt.title('Dataset')
```

**Dataset:**

<img src="/assets/images/bai11/anh6.png" class="normalpic"/>

<p align="center"> <b>Hình 6</b>: Dataset</p>

### 5.1. Implement thuật toán

- Trước tiên ta cần một số biến để lưu trữ thông tin cần thiết như: nhãn của toàn tập dữ liệu, đánh dấu xem điểm đang xét tới đã được xét trước đó hay chưa, nhãn của các border point.

```python
labels = np.array([0]*len(true_labels))
visited = np.array([False]*len(true_labels))
labels_border = []
```

- Hàm tính khoảng cách giữa 2 điểm:

```python
# Calculate distance by norm 2 of two points
def distance(p1,p2):
    return np.linalg.norm(p1-p2,2)
```

- Hàm lấy ra vùng lân cận của điểm $p$ đang xét tới:

```python
# Find nearest neighbors that have distance <= epsilon of point
def nearestNeighbors(data, p, eps):
    neighbors = []
    for i,point in enumerate(data):
        if distance(point, p) <= eps:
            neighbors.append(i)
    return neighbors
```

- Hàm xử lí thuật toán của DBSCAN, như mình đã trình bày các bước thì ở hàm này nhiệm vụ sẽ đi đánh nhãn cho mỗi điểm dữ liệu dựa trên mật độ và lan rộng từ core point ra các điểm xung quanh từ đó thuật toán sẽ chủ yếu lặp đi lặp lại bước này tới hết toàn bộ dữ liệu được xét (lưu ý các điểm noise ở phần code sẽ có nhãn là -1 và nếu biến visited để kiểm tra xem điểm đó đã được xét hay chưa)

```python
# Main algorithm - DBSCAN
def dbscan(data, eps, minPoints):
    c = 0 # label for each dense density
    for i in range(len(data)):
        p = data[i]
        if visited[i] == True: # this point was visited
            continue
        visited[i] = True # change point status to visited
        neighbors = nearestNeighbors(data, p, eps) # nearest neighbors of point
        if len(neighbors) < minPoints:
            labels[i] = -1 # this is noise point
            continue
        labels[i] = c # core point
        neighbors.remove(i) # remove current core point
        S = neighbors
        # spread from core point
        for j in S:
            if visited[j] == True:
                continue
            labels[j] = c # change point's label of nearest core point
            neighbors = nearestNeighbors(data, data[j], eps) # nearest neighbors of nearest core point
            if len(neighbors) >= minPoints:
                S += neighbors # spread from core point more
            else:
                labels_border.append(j) # this is boder point
            S.remove(j) # remove current core point
            visited[j] = True # change point status to visited
        c += 1 # new cluster initalizes 
```

- Nếu mới đọc đoạn code hàm `dbscan` thì có chút bối rối, nhưng bạn có thể vẽ một chút và dựa trên bản chất lan theo mật độ thì nó khá dễ đấy. Bây giờ mình sẽ gọi hàm `dbscan` và visualize kết quả:

```python
# For visualize
fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10, 4.5))
ax1.plot(X[:, 0], X[:, 1], 'o')
ax1.set_title('Before')

# Main algorithm
eps=0.3
minPoints=10
dbscan(X, eps, minPoints)

# For visualize
n_noise_ = list(labels).count(-1)
core_samples_mask = np.ones_like(labels, dtype=bool)
core_samples_mask[np.array(labels_border)] = False
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
unique_labels = set(labels)
colors = [plt.cm.Spectral(each)
          for each in np.linspace(0, 1, len(unique_labels))]

for k, col in zip(unique_labels, colors):
    if k == -1:
        # Black used for noise.
        col = [0, 0, 0, 1]

    class_member_mask = (labels == k)

    xy = X[class_member_mask & core_samples_mask]
    ax2.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),
             markeredgecolor='k', markersize=6)

    xy = X[class_member_mask & ~core_samples_mask]
    ax2.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),
             markeredgecolor='k', markersize=6)

ax2.set_title('After')
plt.show()
```

**Kết quả:**

- Kết quả khá tốt, những điểm ngoại lai màu đen chính là các outlier ta đã tìm được

<img src="/assets/images/bai11/test1.png" class="large"/>

<p align="center"> <b>Hình 7</b>: DBSCAN implement</p>

- Mình sẽ in ra số lượng điểm outlier, boder point để lát kiểm tra với thư viện sklearn:

```python
print('Number of outlier: ', n_noise_)
print('Number of boder: ', len(labels_border))
print('Number of core: ', len(labels) - len(labels_border) - n_noise_)
```

```python
Number of outlier:  22
Number of boder:  56
Number of core:  672
```

### 5.2. Nghiệm bằng thư viện scikit-learn

```python
import numpy as np 
from sklearn.cluster import DBSCAN 
from sklearn.datasets import make_blobs 
import matplotlib.pyplot as plt 
  
# dataset
centers = [[1, 1], [-1, -1], [1, -1]] 
X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4, random_state=0)

# For visualize
fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10, 4.5))
ax1.plot(X[:, 0], X[:, 1], 'o')
ax1.set_title('Before')

# Init DBSCAN model and fit
db = DBSCAN(eps=0.3, min_samples=10).fit(X)

# For visualize
core_samples_mask = np.zeros_like(db.labels_, dtype=bool)
core_samples_mask[db.core_sample_indices_] = True
labels = db.labels_
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
n_noise_ = list(labels).count(-1)

unique_labels = set(labels)
colors = [plt.cm.Spectral(each)
          for each in np.linspace(0, 1, len(unique_labels))]

for k, col in zip(unique_labels, colors):
    if k == -1:
        # Black used for noise.
        col = [0, 0, 0, 1]

    class_member_mask = (labels == k)

    xy = X[class_member_mask & core_samples_mask]
    ax2.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),
             markeredgecolor='k', markersize=14)

    xy = X[class_member_mask & ~core_samples_mask]
    ax2.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),
             markeredgecolor='k', markersize=6)

ax2.set_title('After')
plt.show()
```

**Kết quả:**

- Như đã thấy thì kết quả của DBSCAN khi sử dụng sklearn cho kết quả giống với cách mình đã implement ở trên

<img src="/assets/images/bai11/test1.png" class="large"/>

<p align="center"> <b>Hình 8</b>: DBSCAN sklearn</p>

- Để chắc chắn mình sẽ in số lượng các điểm outlier, boder, core

```python
print('Number of outlier: ', n_noise_)
print('Number of boder: ', len(labels) - len(db.core_sample_indices_) - n_noise_)
print('Number of core: ', len(db.core_sample_indices_))
```

```python
Number of outlier:  22
Number of boder:  56
Number of core:  672
```

https://www.geeksforgeeks.org/difference-between-k-means-and-dbscan-clustering/

https://www.digitalvidya.com/blog/the-top-5-clustering-algorithms-data-scientists-should-know/

https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf

https://www.digitalvidya.com/blog/the-top-5-clustering-algorithms-data-scientists-should-know/